{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CIFAR-10 Image Classification with ConvNeXt and Optuna\n",
        "\n",
        "This notebook demonstrates training a ConvNeXt classifier on the CIFAR-10 dataset using Optuna for hyperparameter tuning.  The dataset is exported from the original CIFAR-10 binary batches into a folder structure with separate `train`, `val`, and `test` splits.  Throughout the tuning and final training runs, detailed metrics (loss, accuracy, precision, recall, F1, and specificity) are logged for each epoch.  Curves and confusion matrices are automatically generated and stored in the `./artifacts` directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies\n",
        "\n",
        "Install necessary Python packages.  This cell uses `pip` via the `%uv` magic to ensure dependencies are available for the rest of the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "%uv pip install timm optuna scikit-learn torchmetrics jiwer opencv-python tqdm matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtimm==1.0.21                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2moptuna==4.5.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mscikit-learn==1.7.1                                                           \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtorchmetrics==1.8.2                                                           \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mjiwer==4.0.0                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mopencv-python==4.12.0.88                                                      \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mmatplotlib==3.10.6                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mmatplotlib==3.10.6                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mtorch==2.8.0+cu129                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mtorchvision==0.23.0+cu129                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mpyyaml==6.0.2                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2mhuggingface-hub==0.34.4                                                       \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2msafetensors==0.6.2                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2839\u001b[0m \u001b[2malembic==1.17.0                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2malembic==1.17.0                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mcolorlog==6.10.1                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mnumpy==2.1.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mnumpy==2.1.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mpackaging==25.0                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2msqlalchemy==2.0.43                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mscipy==1.16.1                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mjoblib==1.5.2                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mthreadpoolctl==3.6.0                                                          \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mlightning-utilities==0.15.2                                                   \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mclick==8.2.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2838\u001b[0m \u001b[2mnvidia-cublas-cu12==12.9.1.4                                                  \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m64 packages\u001b[0m \u001b[2min 482ms\u001b[0m\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)                                                  \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)                                                  \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/28.74 KiB            \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB          \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/76.67 KiB                     \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB                   \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB                      \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB                      \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB                      \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/3.01 MiB                      \u001b[5A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[5A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[5A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[5A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[6A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[6A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[6A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[6A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[8A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[8A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 14.92 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[8A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[8A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 14.92 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/63.94 MiB                  \u001b[9A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[9A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 14.92 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.90 KiB/63.94 MiB                \u001b[9A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[9A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mcolorlog  \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 11.47 KiB/11.47 KiB\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 14.92 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 31.89 KiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 56.13 KiB/63.94 MiB                \u001b[10A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[10A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mcolorlog  \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 11.47 KiB/11.47 KiB\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 22.49 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 30.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 30.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 32.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 32.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 72.74 KiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 502.21 KiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.70 MiB/63.94 MiB                 \u001b[10A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[10A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 22.49 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 46.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 46.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 32.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 48.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 168.74 KiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 1.02 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.25 MiB/63.94 MiB                 \u001b[9A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[9A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 62.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 62.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 32.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 48.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 296.74 KiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 1.02 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.47 MiB/63.94 MiB                 \u001b[8A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[8A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 28.74 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 62.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 62.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 32.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 63.66 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 376.74 KiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.24 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.47 MiB/63.94 MiB                 \u001b[8A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[8A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 28.74 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 76.67 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 94.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 48.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 88.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.12 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.35 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.14 MiB/63.94 MiB                 \u001b[8A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[8A\u001b[37m\u2839\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 76.67 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 94.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 88.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 1.41 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.35 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.94 MiB/63.94 MiB                 \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m\u2839\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 76.67 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 126.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 104.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.49 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.35 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.06 MiB/63.94 MiB                 \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m\u2839\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 76.67 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 142.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 120.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.49 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.35 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 7.18 MiB/63.94 MiB                 \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m\u2839\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 76.67 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 158.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 124.36 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.51 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.35 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 9.94 MiB/63.94 MiB                 \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m\u2839\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 174.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 136.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.51 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.37 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 11.30 MiB/63.94 MiB                \u001b[6A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[6A\u001b[37m\u2839\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 174.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 152.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.52 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.37 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 12.16 MiB/63.94 MiB                \u001b[6A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[6A\u001b[37m\u2838\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 190.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 80.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 200.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1.56 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.51 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.82 MiB/63.94 MiB                \u001b[6A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[6A\u001b[37m\u2838\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 206.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 96.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 248.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1.60 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.82 MiB/63.94 MiB                \u001b[5A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[5A\u001b[37m\u2838\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 144.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 328.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.63 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.86 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u2838\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 160.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 344.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.63 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.86 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u2838\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 224.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 424.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.71 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 15.40 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u2838\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 240.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 440.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.74 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 17.11 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u283c\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 240.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 456.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.76 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 20.35 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u283c\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 352.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 584.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 2.15 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.35 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m\u283c\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 616.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 2.21 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.35 MiB/63.94 MiB                \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A\u001b[37m\u283c\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 776.40 KiB/960.12 KiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.82 MiB/63.94 MiB                \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u283c\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 808.40 KiB/960.12 KiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 22.00 MiB/63.94 MiB                \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m\u283c\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 22.00 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u283c\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 23.58 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2834\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 26.01 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2834\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 27.75 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2834\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 30.06 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2826\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 32.92 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2826\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 36.02 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2826\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 39.02 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2826\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 41.22 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2826\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 44.27 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2827\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 46.93 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2827\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 49.74 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2827\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 52.25 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2827\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 54.72 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2807\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 57.87 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2807\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 59.11 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2807\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 61.94 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2807\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)                                                  \r\u001b[2K\u001b[2mPrepared \u001b[1m10 packages\u001b[0m \u001b[2min 1.58s\u001b[0m\u001b[0m\r\n",
            "\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/10] \u001b[2mInstalling wheels...                                \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/10] \u001b[2mcolorlog==6.10.1                                    \u001b[0m\r\u001b[2K\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [1/10] \u001b[2mcolorlog==6.10.1                                    \u001b[0m\r\u001b[2K\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [1/10] \u001b[2mjiwer==4.0.0                                        \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [2/10] \u001b[2mjiwer==4.0.0                                        \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [2/10] \u001b[2mlightning-utilities==0.15.2                         \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [3/10] \u001b[2mlightning-utilities==0.15.2                         \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [3/10] \u001b[2mmako==1.3.10                                        \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [4/10] \u001b[2mmako==1.3.10                                        \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [4/10] \u001b[2mrapidfuzz==3.14.1                                   \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [5/10] \u001b[2mrapidfuzz==3.14.1                                   \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [5/10] \u001b[2malembic==1.17.0                                     \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [6/10] \u001b[2malembic==1.17.0                                     \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [6/10] \u001b[2mopencv-python==4.12.0.88                            \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591 [7/10] \u001b[2mopencv-python==4.12.0.88                            \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591 [7/10] \u001b[2moptuna==4.5.0                                       \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 [8/10] \u001b[2moptuna==4.5.0                                       \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 [8/10] \u001b[2mtimm==1.0.21                                        \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591 [9/10] \u001b[2mtimm==1.0.21                                        \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591 [9/10] \u001b[2mtorchmetrics==1.8.2                                 \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 [10/10] \u001b[2mtorchmetrics==1.8.2                                \u001b[0m\r\u001b[2K\u001b[2mInstalled \u001b[1m10 packages\u001b[0m \u001b[2min 184ms\u001b[0m\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1malembic\u001b[0m\u001b[2m==1.17.0\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorlog\u001b[0m\u001b[2m==6.10.1\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mjiwer\u001b[0m\u001b[2m==4.0.0\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mlightning-utilities\u001b[0m\u001b[2m==0.15.2\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mmako\u001b[0m\u001b[2m==1.3.10\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.12.0.88\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1moptuna\u001b[0m\u001b[2m==4.5.0\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mrapidfuzz\u001b[0m\u001b[2m==3.14.1\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mtimm\u001b[0m\u001b[2m==1.0.21\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchmetrics\u001b[0m\u001b[2m==1.8.2\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Basic Utilities\n",
        "\n",
        "Import required libraries and define helper functions for seeding and device selection.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import optuna\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Mixed precision scaler (PyTorch 2.5+)\n",
        "from torch import amp\n",
        "SCALER = amp.GradScaler('cuda', enabled=True)\n",
        "\n",
        "def seed_everything(seed: int = 42) -> None:\n",
        "    \"\"\"Seed all random number generators for reproducibility.\"\"\"\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def device_auto() -> torch.device:\n",
        "    \"\"\"Return the available device: CUDA if present, else CPU.\"\"\"\n",
        "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset and Transform Classes\n",
        "\n",
        "Define a simple classification transform and a dataset class that reads from a folder structure organized as `<root>/<split>/<class>/<images>`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "class ClassificationTransform:\n",
        "    \"\"\"Apply random augmentation and normalisation for classification.\"\"\"\n",
        "    def __init__(self, size: int = 224, train: bool = True) -> None:\n",
        "        self.size = size\n",
        "        self.train = train\n",
        "\n",
        "    def __call__(self, img_bgr: np.ndarray) -> torch.Tensor:\n",
        "        # Convert BGR (OpenCV) to RGB (PIL)\n",
        "        img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "        if self.train:\n",
        "            h, w = img.shape[:2]\n",
        "            # Random scale crop\n",
        "            scale = np.random.uniform(0.7, 1.0)\n",
        "            nh, nw = int(h * scale), int(w * scale)\n",
        "            y0 = np.random.randint(0, max(1, h - nh + 1))\n",
        "            x0 = np.random.randint(0, max(1, w - nw + 1))\n",
        "            img = img[y0:y0 + nh, x0:x0 + nw]\n",
        "            # Random brightness/contrast\n",
        "            if np.random.rand() < 0.5:\n",
        "                alpha = np.random.uniform(0.8, 1.2)  # contrast\n",
        "                beta = np.random.randint(-20, 20)    # brightness\n",
        "                img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
        "            # Random horizontal flip\n",
        "            if np.random.rand() < 0.5:\n",
        "                img = img[:, ::-1, :]\n",
        "        # Resize to target size\n",
        "        img = cv2.resize(img, (self.size, self.size), interpolation=cv2.INTER_LINEAR)\n",
        "        # Convert to tensor and normalise\n",
        "        t = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32) / 255.0\n",
        "        # Normalise using ImageNet mean and std\n",
        "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "        std  = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "        t = (t - mean) / std\n",
        "        return t\n",
        "\n",
        "class ClassificationDataset(Dataset):\n",
        "    \"\"\"A dataset for image classification organised as <root>/<split>/<class>/<images>.\"\"\"\n",
        "    def __init__(self, root: str, split: str, transform: ClassificationTransform, class_to_idx: Dict[str, int] = None) -> None:\n",
        "        self.root = Path(root)\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.samples: List[Tuple[str, int]] = []\n",
        "        # Build class mapping\n",
        "        if class_to_idx is None:\n",
        "            classes = sorted([p.name for p in (self.root / split).iterdir() if p.is_dir()])\n",
        "            self.class_to_idx = {c: i for i, c in enumerate(classes)}\n",
        "        else:\n",
        "            self.class_to_idx = dict(class_to_idx)\n",
        "            # Ensure directory exists for every class\n",
        "            for c in self.class_to_idx.keys():\n",
        "                (self.root / split / c).mkdir(parents=True, exist_ok=True)\n",
        "        # Collect samples (image path, label)\n",
        "        for cls, idx in self.class_to_idx.items():\n",
        "            class_dir = self.root / split / cls\n",
        "            if not class_dir.exists():\n",
        "                continue\n",
        "            for imgp in class_dir.glob(\"*.*\"):\n",
        "                if imgp.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"]:\n",
        "                    self.samples.append((str(imgp), idx))\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
        "        path, label = self.samples[idx]\n",
        "        img_bgr = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "        if img_bgr is None:\n",
        "            raise FileNotFoundError(path)\n",
        "        x = self.transform(img_bgr)\n",
        "        return x, label\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Evaluation Functions\n",
        "\n",
        "Define functions to train the model for one epoch and to evaluate it on a dataset, computing common metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "@torch.no_grad()\n",
        "def eval_cls_metrics(model: nn.Module, loader: DataLoader, criterion: nn.Module, device: torch.device) -> Dict[str, float]:\n",
        "    \"\"\"Evaluate a classification model and compute common metrics.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    losses = 0.0\n",
        "    nobs = 0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = torch.as_tensor(y, dtype=torch.long, device=device)\n",
        "        with amp.autocast('cuda', dtype=torch.float16, enabled=True):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        losses += float(loss.item()) * x.size(0)\n",
        "        nobs += x.size(0)\n",
        "        all_preds.append(logits.argmax(1).detach().cpu().numpy())\n",
        "        all_labels.append(y.detach().cpu().numpy())\n",
        "    y_pred = np.concatenate(all_preds) if all_preds else np.array([])\n",
        "    y_true = np.concatenate(all_labels) if all_labels else np.array([])\n",
        "    val_loss = losses / max(1, nobs)\n",
        "\n",
        "    if y_true.size == 0:\n",
        "        return {\"loss\": val_loss, \"acc\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"specificity\": None}\n",
        "\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    cm   = confusion_matrix(y_true, y_pred)\n",
        "    spec = None\n",
        "    if cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        spec = tn / (tn + fp + 1e-12)\n",
        "    return {\"loss\": val_loss, \"acc\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"specificity\": spec}\n",
        "\n",
        "\n",
        "def train_one_epoch_cls(model: nn.Module, loader: DataLoader, opt: torch.optim.Optimizer, criterion: nn.Module,\n",
        "                        device: torch.device, epoch: int, epochs: int) -> Tuple[float, float]:\n",
        "    \"\"\"Train the model for a single epoch and return average loss and accuracy.\"\"\"\n",
        "    model.train()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss_sum = 0.0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = torch.as_tensor(y, dtype=torch.long, device=device)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with amp.autocast('cuda', dtype=torch.float16, enabled=True):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        SCALER.scale(loss).backward()\n",
        "        SCALER.step(opt)\n",
        "        SCALER.update()\n",
        "        loss_sum += float(loss.item()) * x.size(0)\n",
        "        preds = logits.argmax(1)\n",
        "        correct += int((preds == y).sum().item())\n",
        "        total += x.size(0)\n",
        "    avg_loss = loss_sum / max(1, total)\n",
        "    acc = correct / max(1, total)\n",
        "    return avg_loss, acc\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build ConvNeXt Model\n",
        "\n",
        "Select a ConvNeXt variant and define a helper to instantiate it with a custom dropout rate and number of classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# Choose a ConvNeXt variant: 'convnext_tiny', 'convnext_small', or 'convnext_base'\n",
        "MANUAL_CONVNEXT_VARIANT = 'convnext_tiny'\n",
        "\n",
        "def build_convnext_classifier(variant: str, num_classes: int, dropout: float) -> nn.Module:\n",
        "    \"\"\"Create a ConvNeXt model for classification using timm.\"\"\"\n",
        "    model = timm.create_model(variant, pretrained=True, num_classes=num_classes, drop_rate=dropout)\n",
        "    return model\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export CIFAR-10 to Train/Val/Test Folders\n",
        "\n",
        "The CIFAR-10 dataset is originally provided in a binary format.  This cell exports the dataset into a folder structure with separate `train`, `val`, and `test` splits.  The validation set is created by splitting the original test set in half.  Set `overwrite=False` to skip regeneration if the export already exists.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# CIFAR-10 export settings\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "# Paths\n",
        "batches_dir = Path(\"/root/data/cifar10/cifar-10-batches-py\")  # CIFAR-10 binary batches location\n",
        "export_root = Path(\"/root/data/cifar10_extracted\")\n",
        "overwrite = False  # set True to re-export\n",
        "val_fraction = 0.5  # fraction of test set to use for validation\n",
        "\n",
        "# Ensure parent folder exists\n",
        "batches_dir.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# \u2705 If CIFAR-10 not found locally, download it first\n",
        "if not batches_dir.exists():\n",
        "    print(\"[INFO] CIFAR-10 not found locally. Downloading...\")\n",
        "    datasets.CIFAR10(root=str(batches_dir.parent), train=True, download=True)\n",
        "    datasets.CIFAR10(root=str(batches_dir.parent), train=False, download=True)\n",
        "else:\n",
        "    print(\"[OK] CIFAR-10 already exists locally.\")\n",
        "\n",
        "root_for_torchvision = batches_dir.parent  # torchvision will find 'cifar-10-batches-py' under this root\n",
        "\n",
        "# Export if needed\n",
        "if export_root.exists() and not overwrite:\n",
        "    print(f\"[SKIP] {export_root} already exists. Set overwrite=True to re-export.\")\n",
        "else:\n",
        "    # Remove existing and recreate\n",
        "    if export_root.exists():\n",
        "        shutil.rmtree(export_root)\n",
        "    (export_root / \"train\").mkdir(parents=True, exist_ok=True)\n",
        "    (export_root / \"val\").mkdir(parents=True, exist_ok=True)\n",
        "    (export_root / \"test\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load CIFAR-10 from existing or freshly downloaded batches\n",
        "    ds_train = datasets.CIFAR10(root=str(root_for_torchvision), train=True, download=False)\n",
        "    ds_test  = datasets.CIFAR10(root=str(root_for_torchvision), train=False, download=False)\n",
        "    classes = ds_train.classes\n",
        "    print(\"CIFAR-10 classes:\", classes)\n",
        "\n",
        "    # Split test dataset into val/test\n",
        "    indices = np.random.permutation(len(ds_test))\n",
        "    val_size = int(len(ds_test) * val_fraction)\n",
        "    val_indices = indices[:val_size]\n",
        "    test_indices = indices[val_size:]\n",
        "\n",
        "    # Helper to export a portion of a dataset\n",
        "    def export_dataset(dataset, indices, split_name: str):\n",
        "        for c in classes:\n",
        "            (export_root / split_name / c).mkdir(parents=True, exist_ok=True)\n",
        "        for idx in tqdm(indices, desc=f\"Exporting {split_name}\"):\n",
        "            img, label = dataset[idx]\n",
        "            cls = classes[label]\n",
        "            out_path = export_root / split_name / cls / f\"{split_name}_{cls}_{idx:05d}.png\"\n",
        "            img.save(out_path, format=\"PNG\", optimize=True)\n",
        "\n",
        "    # Export train\n",
        "    for c in classes:\n",
        "        (export_root / \"train\" / c).mkdir(parents=True, exist_ok=True)\n",
        "    for idx in tqdm(range(len(ds_train)), desc=\"Exporting train\"):\n",
        "        img, label = ds_train[idx]\n",
        "        cls = classes[label]\n",
        "        out_path = export_root / \"train\" / cls / f\"train_{cls}_{idx:05d}.png\"\n",
        "        img.save(out_path, format=\"PNG\", optimize=True)\n",
        "\n",
        "    # Export validation and test splits\n",
        "    export_dataset(ds_test, val_indices, \"val\")\n",
        "    export_dataset(ds_test, test_indices, \"test\")\n",
        "\n",
        "print(f\"[DONE] CIFAR-10 exported to: {export_root.resolve()}\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] CIFAR-10 not found locally. Downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|                                                                               | 0.00/170M [00:00<?, ?B/s]\r  0%|\u258f                                                                      | 459k/170M [00:00<00:37, 4.51MB/s]\r  3%|\u2588\u2588\u258e                                                                   | 5.64M/170M [00:00<00:05, 32.1MB/s]\r  6%|\u2588\u2588\u2588\u2589                                                                  | 9.67M/170M [00:00<00:04, 35.8MB/s]\r  8%|\u2588\u2588\u2588\u2588\u2588\u258b                                                                | 13.9M/170M [00:00<00:04, 38.3MB/s]\r 10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                              | 17.8M/170M [00:00<00:04, 35.6MB/s]\r 13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                             | 21.8M/170M [00:00<00:04, 37.1MB/s]\r 15%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                           | 26.0M/170M [00:00<00:03, 38.5MB/s]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                         | 29.9M/170M [00:00<00:03, 38.3MB/s]\r 20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                        | 33.9M/170M [00:00<00:03, 38.8MB/s]\r 22%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                      | 37.8M/170M [00:01<00:03, 37.8MB/s]\r 25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                    | 42.2M/170M [00:01<00:03, 39.7MB/s]\r 27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                   | 46.5M/170M [00:01<00:03, 40.5MB/s]\r 30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                 | 50.8M/170M [00:01<00:02, 41.1MB/s]\r 32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                               | 54.9M/170M [00:01<00:03, 36.7MB/s]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                             | 58.9M/170M [00:01<00:02, 37.5MB/s]\r 37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                            | 62.9M/170M [00:01<00:02, 38.3MB/s]\r 40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                          | 67.4M/170M [00:01<00:02, 40.1MB/s]\r 42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                        | 71.5M/170M [00:01<00:02, 38.4MB/s]\r 44%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                       | 75.4M/170M [00:02<00:02, 38.3MB/s]\r 46%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                     | 79.2M/170M [00:02<00:02, 37.0MB/s]\r 49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                   | 83.9M/170M [00:02<00:02, 39.5MB/s]\r 52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                 | 88.2M/170M [00:02<00:02, 40.5MB/s]\r 54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                | 92.3M/170M [00:02<00:01, 39.6MB/s]\r 57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 97.2M/170M [00:02<00:01, 42.3MB/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                            | 101M/170M [00:02<00:01, 42.2MB/s]\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                          | 107M/170M [00:02<00:01, 44.6MB/s]\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                        | 111M/170M [00:02<00:01, 43.4MB/s]\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                      | 116M/170M [00:02<00:01, 43.7MB/s]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                     | 120M/170M [00:03<00:01, 44.2MB/s]\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                   | 125M/170M [00:03<00:01, 43.6MB/s]\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                 | 129M/170M [00:03<00:00, 42.8MB/s]\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b               | 134M/170M [00:03<00:00, 43.8MB/s]\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c             | 138M/170M [00:03<00:00, 40.4MB/s]\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e           | 143M/170M [00:03<00:00, 41.1MB/s]\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d         | 147M/170M [00:03<00:00, 43.3MB/s]\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d       | 152M/170M [00:03<00:00, 44.5MB/s]\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e     | 157M/170M [00:03<00:00, 41.9MB/s]\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588    | 161M/170M [00:04<00:00, 42.1MB/s]\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 166M/170M [00:04<00:00, 43.1MB/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 170M/170M [00:04<00:00, 37.6MB/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 170M/170M [00:04<00:00, 39.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10 classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExporting train:   0%|                                                               | 0/50000 [00:00<?, ?it/s]\rExporting train:   0%|\u258f                                                  | 145/50000 [00:00<00:34, 1442.18it/s]\rExporting train:   1%|\u258e                                                  | 310/50000 [00:00<00:31, 1560.08it/s]\rExporting train:   1%|\u258d                                                  | 467/50000 [00:00<00:32, 1513.21it/s]\rExporting train:   1%|\u258b                                                  | 619/50000 [00:00<00:32, 1502.98it/s]\rExporting train:   2%|\u258a                                                  | 779/50000 [00:00<00:32, 1534.46it/s]\rExporting train:   2%|\u2589                                                  | 948/50000 [00:00<00:30, 1583.83it/s]\rExporting train:   2%|\u2588                                                 | 1117/50000 [00:00<00:30, 1617.40it/s]\rExporting train:   3%|\u2588\u258e                                                | 1280/50000 [00:00<00:30, 1620.86it/s]\rExporting train:   3%|\u2588\u258d                                                | 1443/50000 [00:00<00:30, 1608.03it/s]\rExporting train:   3%|\u2588\u258c                                                | 1604/50000 [00:01<00:30, 1583.12it/s]\rExporting train:   4%|\u2588\u258a                                                | 1773/50000 [00:01<00:29, 1614.60it/s]\rExporting train:   4%|\u2588\u2589                                                | 1940/50000 [00:01<00:29, 1629.18it/s]\rExporting train:   4%|\u2588\u2588                                                | 2112/50000 [00:01<00:28, 1654.58it/s]\rExporting train:   5%|\u2588\u2588\u258e                                               | 2279/50000 [00:01<00:28, 1657.66it/s]\rExporting train:   5%|\u2588\u2588\u258d                                               | 2445/50000 [00:01<00:30, 1568.46it/s]\rExporting train:   5%|\u2588\u2588\u258c                                               | 2617/50000 [00:01<00:29, 1611.73it/s]\rExporting train:   6%|\u2588\u2588\u258a                                               | 2795/50000 [00:01<00:28, 1659.42it/s]\rExporting train:   6%|\u2588\u2588\u2589                                               | 2962/50000 [00:01<00:28, 1631.55it/s]\rExporting train:   6%|\u2588\u2588\u2588\u258f                                              | 3126/50000 [00:01<00:28, 1619.10it/s]\rExporting train:   7%|\u2588\u2588\u2588\u258e                                              | 3297/50000 [00:02<00:28, 1643.49it/s]\rExporting train:   7%|\u2588\u2588\u2588\u258d                                              | 3475/50000 [00:02<00:27, 1682.83it/s]\rExporting train:   7%|\u2588\u2588\u2588\u258b                                              | 3654/50000 [00:02<00:27, 1712.72it/s]\rExporting train:   8%|\u2588\u2588\u2588\u258a                                              | 3826/50000 [00:02<00:29, 1550.40it/s]\rExporting train:   8%|\u2588\u2588\u2588\u2589                                              | 3985/50000 [00:02<00:30, 1509.60it/s]\rExporting train:   8%|\u2588\u2588\u2588\u2588\u258f                                             | 4139/50000 [00:02<00:31, 1475.87it/s]\rExporting train:   9%|\u2588\u2588\u2588\u2588\u258e                                             | 4298/50000 [00:02<00:30, 1505.68it/s]\rExporting train:   9%|\u2588\u2588\u2588\u2588\u258d                                             | 4459/50000 [00:02<00:29, 1534.98it/s]\rExporting train:   9%|\u2588\u2588\u2588\u2588\u258b                                             | 4630/50000 [00:02<00:28, 1585.38it/s]\rExporting train:  10%|\u2588\u2588\u2588\u2588\u258a                                             | 4790/50000 [00:03<00:29, 1515.20it/s]\rExporting train:  10%|\u2588\u2588\u2588\u2588\u2589                                             | 4943/50000 [00:03<00:29, 1504.41it/s]\rExporting train:  10%|\u2588\u2588\u2588\u2588\u2588                                             | 5101/50000 [00:03<00:29, 1524.89it/s]\rExporting train:  11%|\u2588\u2588\u2588\u2588\u2588\u258e                                            | 5255/50000 [00:03<00:29, 1492.95it/s]\rExporting train:  11%|\u2588\u2588\u2588\u2588\u2588\u258d                                            | 5405/50000 [00:03<00:30, 1464.94it/s]\rExporting train:  11%|\u2588\u2588\u2588\u2588\u2588\u258c                                            | 5552/50000 [00:03<00:30, 1441.62it/s]\rExporting train:  11%|\u2588\u2588\u2588\u2588\u2588\u258b                                            | 5703/50000 [00:03<00:30, 1459.14it/s]\rExporting train:  12%|\u2588\u2588\u2588\u2588\u2588\u258a                                            | 5865/50000 [00:03<00:29, 1505.00it/s]\rExporting train:  12%|\u2588\u2588\u2588\u2588\u2588\u2588                                            | 6016/50000 [00:03<00:30, 1453.24it/s]\rExporting train:  12%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                           | 6162/50000 [00:03<00:30, 1440.37it/s]\rExporting train:  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                           | 6307/50000 [00:04<00:30, 1412.34it/s]\rExporting train:  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                           | 6449/50000 [00:04<00:31, 1372.44it/s]\rExporting train:  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                           | 6596/50000 [00:04<00:31, 1399.60it/s]\rExporting train:  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                           | 6740/50000 [00:04<00:30, 1410.43it/s]\rExporting train:  14%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                           | 6910/50000 [00:04<00:28, 1493.31it/s]\rExporting train:  14%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 7082/50000 [00:04<00:27, 1558.97it/s]\rExporting train:  15%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                          | 7256/50000 [00:04<00:26, 1611.05it/s]\rExporting train:  15%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                          | 7425/50000 [00:04<00:26, 1632.38it/s]\rExporting train:  15%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                          | 7589/50000 [00:04<00:27, 1545.02it/s]\rExporting train:  15%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                          | 7745/50000 [00:05<00:28, 1486.28it/s]\rExporting train:  16%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                          | 7895/50000 [00:05<00:28, 1460.80it/s]\rExporting train:  16%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                          | 8045/50000 [00:05<00:28, 1469.94it/s]\rExporting train:  16%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                         | 8214/50000 [00:05<00:27, 1531.68it/s]\rExporting train:  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                         | 8379/50000 [00:05<00:26, 1566.10it/s]\rExporting train:  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                         | 8550/50000 [00:05<00:25, 1607.28it/s]\rExporting train:  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                         | 8726/50000 [00:05<00:25, 1650.49it/s]\rExporting train:  18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                         | 8892/50000 [00:05<00:25, 1611.25it/s]\rExporting train:  18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                         | 9054/50000 [00:05<00:25, 1598.05it/s]\rExporting train:  18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                        | 9215/50000 [00:05<00:26, 1534.33it/s]\rExporting train:  19%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                        | 9370/50000 [00:06<00:27, 1492.86it/s]\rExporting train:  19%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                        | 9536/50000 [00:06<00:26, 1537.53it/s]\rExporting train:  19%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                        | 9700/50000 [00:06<00:25, 1564.18it/s]\rExporting train:  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                        | 9869/50000 [00:06<00:25, 1600.76it/s]\rExporting train:  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                       | 10037/50000 [00:06<00:24, 1623.74it/s]\rExporting train:  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                       | 10200/50000 [00:06<00:25, 1570.28it/s]\rExporting train:  21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                      | 10358/50000 [00:06<00:25, 1548.19it/s]\rExporting train:  21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                      | 10532/50000 [00:06<00:24, 1602.83it/s]\rExporting train:  21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                      | 10705/50000 [00:06<00:23, 1639.20it/s]\rExporting train:  22%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                      | 10870/50000 [00:07<00:25, 1554.56it/s]\rExporting train:  22%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                      | 11027/50000 [00:07<00:26, 1467.94it/s]\rExporting train:  22%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                      | 11187/50000 [00:07<00:25, 1503.86it/s]\rExporting train:  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                      | 11339/50000 [00:07<00:26, 1457.55it/s]\rExporting train:  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                     | 11486/50000 [00:07<00:26, 1438.50it/s]\rExporting train:  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                     | 11631/50000 [00:07<00:27, 1412.94it/s]\rExporting train:  24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                     | 11781/50000 [00:07<00:26, 1434.59it/s]\rExporting train:  24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                     | 11943/50000 [00:07<00:25, 1487.90it/s]\rExporting train:  24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                     | 12116/50000 [00:07<00:24, 1557.24it/s]\rExporting train:  25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                     | 12279/50000 [00:07<00:23, 1577.70it/s]\rExporting train:  25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                    | 12443/50000 [00:08<00:23, 1593.78it/s]\rExporting train:  25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                    | 12604/50000 [00:08<00:23, 1597.60it/s]\rExporting train:  26%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                    | 12774/50000 [00:08<00:22, 1627.32it/s]\rExporting train:  26%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                    | 12947/50000 [00:08<00:22, 1656.49it/s]\rExporting train:  26%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 13115/50000 [00:08<00:22, 1660.28it/s]\rExporting train:  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                    | 13282/50000 [00:08<00:23, 1596.16it/s]\rExporting train:  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                   | 13443/50000 [00:08<00:23, 1526.65it/s]\rExporting train:  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                   | 13603/50000 [00:08<00:23, 1546.17it/s]\rExporting train:  28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                   | 13776/50000 [00:08<00:22, 1597.52it/s]\rExporting train:  28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                   | 13937/50000 [00:08<00:23, 1565.27it/s]\rExporting train:  28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                   | 14095/50000 [00:09<00:23, 1514.96it/s]\rExporting train:  28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                   | 14248/50000 [00:09<00:23, 1495.25it/s]\rExporting train:  29%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                   | 14398/50000 [00:09<00:24, 1447.63it/s]\rExporting train:  29%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                  | 14544/50000 [00:09<00:24, 1441.01it/s]\rExporting train:  29%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                  | 14701/50000 [00:09<00:23, 1476.31it/s]\rExporting train:  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 14878/50000 [00:09<00:22, 1559.35it/s]\rExporting train:  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                  | 15057/50000 [00:09<00:21, 1625.09it/s]\rExporting train:  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                  | 15228/50000 [00:09<00:21, 1648.14it/s]\rExporting train:  31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                  | 15394/50000 [00:09<00:21, 1640.07it/s]\rExporting train:  31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                 | 15559/50000 [00:10<00:21, 1636.42it/s]\rExporting train:  31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                 | 15723/50000 [00:10<00:21, 1572.07it/s]\rExporting train:  32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                 | 15881/50000 [00:10<00:23, 1471.28it/s]\rExporting train:  32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                 | 16035/50000 [00:10<00:22, 1489.69it/s]\rExporting train:  32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                 | 16196/50000 [00:10<00:22, 1521.22it/s]\rExporting train:  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                 | 16350/50000 [00:10<00:22, 1475.23it/s]\rExporting train:  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                | 16499/50000 [00:10<00:23, 1427.50it/s]\rExporting train:  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                | 16658/50000 [00:10<00:22, 1473.19it/s]\rExporting train:  34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                | 16808/50000 [00:10<00:22, 1480.06it/s]\rExporting train:  34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                | 16957/50000 [00:11<00:22, 1447.48it/s]\rExporting train:  34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                | 17103/50000 [00:11<00:22, 1434.33it/s]\rExporting train:  35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                | 17255/50000 [00:11<00:22, 1457.21it/s]\rExporting train:  35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                | 17402/50000 [00:11<00:22, 1440.42it/s]\rExporting train:  35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                               | 17547/50000 [00:11<00:23, 1394.62it/s]\rExporting train:  35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                               | 17703/50000 [00:11<00:22, 1441.17it/s]\rExporting train:  36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                               | 17850/50000 [00:11<00:22, 1447.31it/s]\rExporting train:  36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                               | 18022/50000 [00:11<00:20, 1525.48it/s]\rExporting train:  36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                               | 18192/50000 [00:11<00:20, 1576.31it/s]\rExporting train:  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                               | 18378/50000 [00:11<00:19, 1659.36it/s]\rExporting train:  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                              | 18545/50000 [00:12<00:19, 1652.03it/s]\rExporting train:  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                              | 18719/50000 [00:12<00:18, 1676.40it/s]\rExporting train:  38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                              | 18892/50000 [00:12<00:18, 1690.73it/s]\rExporting train:  38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                              | 19067/50000 [00:12<00:18, 1706.74it/s]\rExporting train:  38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                              | 19238/50000 [00:12<00:18, 1690.50it/s]\rExporting train:  39%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                              | 19408/50000 [00:12<00:18, 1651.89it/s]\rExporting train:  39%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                             | 19574/50000 [00:12<00:19, 1574.13it/s]\rExporting train:  39%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                             | 19741/50000 [00:12<00:18, 1600.16it/s]\rExporting train:  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                             | 19902/50000 [00:12<00:19, 1557.48it/s]\rExporting train:  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                             | 20067/50000 [00:12<00:18, 1581.74it/s]\rExporting train:  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                             | 20249/50000 [00:13<00:18, 1648.90it/s]\rExporting train:  41%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                             | 20427/50000 [00:13<00:17, 1686.26it/s]\rExporting train:  41%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                            | 20599/50000 [00:13<00:17, 1694.14it/s]\rExporting train:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                            | 20775/50000 [00:13<00:17, 1711.78it/s]\rExporting train:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 20950/50000 [00:13<00:16, 1721.72it/s]\rExporting train:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                            | 21126/50000 [00:13<00:16, 1732.39it/s]\rExporting train:  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                            | 21300/50000 [00:13<00:16, 1731.81it/s]\rExporting train:  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                            | 21474/50000 [00:13<00:16, 1721.77it/s]\rExporting train:  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                           | 21647/50000 [00:13<00:16, 1721.89it/s]\rExporting train:  44%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                           | 21820/50000 [00:13<00:16, 1716.78it/s]\rExporting train:  44%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                           | 21998/50000 [00:14<00:16, 1735.35it/s]\rExporting train:  44%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                           | 22172/50000 [00:14<00:16, 1728.85it/s]\rExporting train:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                           | 22356/50000 [00:14<00:15, 1761.39it/s]\rExporting train:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                           | 22537/50000 [00:14<00:15, 1775.38it/s]\rExporting train:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                          | 22715/50000 [00:14<00:15, 1763.34it/s]\rExporting train:  46%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                          | 22892/50000 [00:14<00:15, 1696.73it/s]\rExporting train:  46%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                          | 23063/50000 [00:14<00:15, 1699.09it/s]\rExporting train:  46%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                          | 23234/50000 [00:14<00:16, 1630.03it/s]\rExporting train:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                          | 23398/50000 [00:14<00:16, 1588.09it/s]\rExporting train:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                          | 23558/50000 [00:15<00:17, 1491.66it/s]\rExporting train:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 23709/50000 [00:15<00:18, 1433.63it/s]\rExporting train:  48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                         | 23854/50000 [00:15<00:18, 1425.31it/s]\rExporting train:  48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                         | 23998/50000 [00:15<00:18, 1411.05it/s]\rExporting train:  48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                         | 24141/50000 [00:15<00:18, 1415.54it/s]\rExporting train:  49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                         | 24287/50000 [00:15<00:18, 1427.78it/s]\rExporting train:  49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                         | 24431/50000 [00:15<00:17, 1429.83it/s]\rExporting train:  49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                         | 24583/50000 [00:15<00:17, 1453.47it/s]\rExporting train:  49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                        | 24729/50000 [00:15<00:17, 1413.30it/s]\rExporting train:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                        | 24894/50000 [00:15<00:16, 1480.58it/s]\rExporting train:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                        | 25043/50000 [00:16<00:17, 1432.01it/s]\rExporting train:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                        | 25190/50000 [00:16<00:17, 1442.76it/s]\rExporting train:  51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                        | 25335/50000 [00:16<00:17, 1439.69it/s]\rExporting train:  51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                        | 25480/50000 [00:16<00:17, 1412.39it/s]\rExporting train:  51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                       | 25638/50000 [00:16<00:16, 1460.44it/s]\rExporting train:  52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                       | 25802/50000 [00:16<00:16, 1510.39it/s]\rExporting train:  52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                       | 25972/50000 [00:16<00:15, 1564.91it/s]\rExporting train:  52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                       | 26145/50000 [00:16<00:14, 1613.15it/s]\rExporting train:  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                       | 26313/50000 [00:16<00:14, 1631.44it/s]\rExporting train:  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                       | 26495/50000 [00:17<00:13, 1685.51it/s]\rExporting train:  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                      | 26664/50000 [00:17<00:14, 1644.26it/s]\rExporting train:  54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                      | 26834/50000 [00:17<00:13, 1658.76it/s]\rExporting train:  54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                      | 27001/50000 [00:17<00:14, 1611.80it/s]\rExporting train:  54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                      | 27163/50000 [00:17<00:14, 1562.00it/s]\rExporting train:  55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                      | 27320/50000 [00:17<00:15, 1485.84it/s]\rExporting train:  55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                      | 27471/50000 [00:17<00:15, 1491.50it/s]\rExporting train:  55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                      | 27621/50000 [00:17<00:15, 1430.68it/s]\rExporting train:  56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                     | 27765/50000 [00:17<00:15, 1427.36it/s]\rExporting train:  56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                     | 27909/50000 [00:17<00:15, 1413.32it/s]\rExporting train:  56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                     | 28057/50000 [00:18<00:15, 1430.60it/s]\rExporting train:  56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                     | 28203/50000 [00:18<00:15, 1438.35it/s]\rExporting train:  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                     | 28376/50000 [00:18<00:14, 1522.48it/s]\rExporting train:  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                     | 28547/50000 [00:18<00:13, 1575.70it/s]\rExporting train:  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                    | 28717/50000 [00:18<00:13, 1611.51it/s]\rExporting train:  58%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 28889/50000 [00:18<00:12, 1641.56it/s]\rExporting train:  58%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                    | 29055/50000 [00:18<00:12, 1646.93it/s]\rExporting train:  58%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                    | 29220/50000 [00:18<00:12, 1602.91it/s]\rExporting train:  59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                    | 29392/50000 [00:18<00:12, 1635.93it/s]\rExporting train:  59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                    | 29578/50000 [00:18<00:12, 1699.61it/s]\rExporting train:  59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                   | 29749/50000 [00:19<00:12, 1679.34it/s]\rExporting train:  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                   | 29918/50000 [00:19<00:12, 1616.93it/s]\rExporting train:  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                   | 30084/50000 [00:19<00:12, 1628.43it/s]\rExporting train:  61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                   | 30265/50000 [00:19<00:11, 1681.27it/s]\rExporting train:  61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                   | 30434/50000 [00:19<00:11, 1673.04it/s]\rExporting train:  61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                   | 30602/50000 [00:19<00:12, 1604.56it/s]\rExporting train:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                  | 30764/50000 [00:19<00:12, 1572.04it/s]\rExporting train:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                  | 30928/50000 [00:19<00:11, 1589.97it/s]\rExporting train:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                  | 31101/50000 [00:19<00:11, 1629.09it/s]\rExporting train:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                  | 31265/50000 [00:20<00:11, 1631.77it/s]\rExporting train:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                  | 31441/50000 [00:20<00:11, 1668.50it/s]\rExporting train:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                  | 31615/50000 [00:20<00:10, 1688.24it/s]\rExporting train:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                 | 31800/50000 [00:20<00:10, 1736.20it/s]\rExporting train:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                 | 31983/50000 [00:20<00:10, 1763.83it/s]\rExporting train:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                 | 32160/50000 [00:20<00:10, 1669.00it/s]\rExporting train:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                 | 32329/50000 [00:20<00:10, 1643.90it/s]\rExporting train:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 32495/50000 [00:20<00:10, 1611.78it/s]\rExporting train:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                 | 32657/50000 [00:20<00:10, 1591.41it/s]\rExporting train:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                | 32817/50000 [00:20<00:11, 1543.18it/s]\rExporting train:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                | 32972/50000 [00:21<00:11, 1540.68it/s]\rExporting train:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                | 33145/50000 [00:21<00:10, 1593.05it/s]\rExporting train:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                | 33318/50000 [00:21<00:10, 1632.90it/s]\rExporting train:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                | 33482/50000 [00:21<00:10, 1620.84it/s]\rExporting train:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                | 33649/50000 [00:21<00:10, 1633.68it/s]\rExporting train:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f               | 33813/50000 [00:21<00:09, 1632.55it/s]\rExporting train:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e               | 33977/50000 [00:21<00:10, 1577.92it/s]\rExporting train:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d               | 34136/50000 [00:21<00:10, 1567.00it/s]\rExporting train:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c               | 34301/50000 [00:21<00:09, 1588.96it/s]\rExporting train:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a               | 34461/50000 [00:22<00:09, 1578.46it/s]\rExporting train:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589               | 34620/50000 [00:22<00:09, 1558.39it/s]\rExporting train:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588               | 34780/50000 [00:22<00:09, 1569.74it/s]\rExporting train:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f              | 34938/50000 [00:22<00:09, 1571.89it/s]\rExporting train:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d              | 35097/50000 [00:22<00:09, 1574.67it/s]\rExporting train:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c              | 35262/50000 [00:22<00:09, 1596.36it/s]\rExporting train:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b              | 35425/50000 [00:22<00:09, 1605.07it/s]\rExporting train:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a              | 35586/50000 [00:22<00:08, 1603.08it/s]\rExporting train:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588              | 35747/50000 [00:22<00:09, 1580.93it/s]\rExporting train:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f             | 35906/50000 [00:22<00:08, 1577.09it/s]\rExporting train:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e             | 36068/50000 [00:23<00:08, 1588.71it/s]\rExporting train:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c             | 36261/50000 [00:23<00:08, 1687.53it/s]\rExporting train:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b             | 36440/50000 [00:23<00:07, 1716.35it/s]\rExporting train:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589             | 36617/50000 [00:23<00:07, 1729.80it/s]\rExporting train:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             | 36791/50000 [00:23<00:07, 1672.87it/s]\rExporting train:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f            | 36964/50000 [00:23<00:07, 1687.30it/s]\rExporting train:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d            | 37134/50000 [00:23<00:07, 1686.24it/s]\rExporting train:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c            | 37303/50000 [00:23<00:07, 1667.68it/s]\rExporting train:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b            | 37475/50000 [00:23<00:07, 1682.04it/s]\rExporting train:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589            | 37644/50000 [00:23<00:07, 1664.39it/s]\rExporting train:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588            | 37811/50000 [00:24<00:07, 1634.87it/s]\rExporting train:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f           | 37975/50000 [00:24<00:07, 1633.78it/s]\rExporting train:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d           | 38139/50000 [00:24<00:07, 1615.02it/s]\rExporting train:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c           | 38302/50000 [00:24<00:07, 1618.00it/s]\rExporting train:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b           | 38464/50000 [00:24<00:07, 1610.62it/s]\rExporting train:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a           | 38626/50000 [00:24<00:07, 1610.03it/s]\rExporting train:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588           | 38788/50000 [00:24<00:07, 1599.71it/s]\rExporting train:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f          | 38949/50000 [00:24<00:06, 1582.16it/s]\rExporting train:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e          | 39117/50000 [00:24<00:06, 1609.28it/s]\rExporting train:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c          | 39299/50000 [00:24<00:06, 1671.08it/s]\rExporting train:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b          | 39467/50000 [00:25<00:06, 1655.06it/s]\rExporting train:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 39633/50000 [00:25<00:06, 1640.52it/s]\rExporting train:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588          | 39798/50000 [00:25<00:06, 1600.20it/s]\rExporting train:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f         | 39959/50000 [00:25<00:06, 1546.03it/s]\rExporting train:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e         | 40115/50000 [00:25<00:06, 1526.40it/s]\rExporting train:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d         | 40276/50000 [00:25<00:06, 1548.86it/s]\rExporting train:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c         | 40432/50000 [00:25<00:06, 1530.38it/s]\rExporting train:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a         | 40587/50000 [00:25<00:06, 1533.86it/s]\rExporting train:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589         | 40746/50000 [00:25<00:05, 1548.46it/s]\rExporting train:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588         | 40905/50000 [00:26<00:05, 1552.20it/s]\rExporting train:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f        | 41061/50000 [00:26<00:05, 1515.11it/s]\rExporting train:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 41217/50000 [00:26<00:05, 1526.33it/s]\rExporting train:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c        | 41376/50000 [00:26<00:05, 1543.25it/s]\rExporting train:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b        | 41531/50000 [00:26<00:05, 1540.93it/s]\rExporting train:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a        | 41686/50000 [00:26<00:05, 1510.78it/s]\rExporting train:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588        | 41838/50000 [00:26<00:05, 1472.89it/s]\rExporting train:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f       | 41986/50000 [00:26<00:05, 1425.64it/s]\rExporting train:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e       | 42130/50000 [00:26<00:05, 1427.99it/s]\rExporting train:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d       | 42274/50000 [00:26<00:05, 1422.36it/s]\rExporting train:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c       | 42422/50000 [00:27<00:05, 1438.70it/s]\rExporting train:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b       | 42591/50000 [00:27<00:04, 1509.86it/s]\rExporting train:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589       | 42755/50000 [00:27<00:04, 1545.50it/s]\rExporting train:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588       | 42919/50000 [00:27<00:04, 1571.80it/s]\rExporting train:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f      | 43077/50000 [00:27<00:04, 1484.82it/s]\rExporting train:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e      | 43227/50000 [00:27<00:04, 1460.20it/s]\rExporting train:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c      | 43374/50000 [00:27<00:04, 1457.89it/s]\rExporting train:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b      | 43521/50000 [00:27<00:04, 1406.30it/s]\rExporting train:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a      | 43676/50000 [00:27<00:04, 1446.86it/s]\rExporting train:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589      | 43822/50000 [00:27<00:04, 1442.18it/s]\rExporting train:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588      | 43967/50000 [00:28<00:04, 1430.62it/s]\rExporting train:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f     | 44115/50000 [00:28<00:04, 1443.67it/s]\rExporting train:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d     | 44267/50000 [00:28<00:03, 1463.67it/s]\rExporting train:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c     | 44415/50000 [00:28<00:03, 1467.37it/s]\rExporting train:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b     | 44565/50000 [00:28<00:03, 1476.69it/s]\rExporting train:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a     | 44723/50000 [00:28<00:03, 1504.99it/s]\rExporting train:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 44888/50000 [00:28<00:03, 1546.50it/s]\rExporting train:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f    | 45044/50000 [00:28<00:03, 1550.49it/s]\rExporting train:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e    | 45210/50000 [00:28<00:03, 1582.58it/s]\rExporting train:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d    | 45369/50000 [00:29<00:02, 1553.80it/s]\rExporting train:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c    | 45525/50000 [00:29<00:03, 1478.38it/s]\rExporting train:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a    | 45674/50000 [00:29<00:02, 1454.21it/s]\rExporting train:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589    | 45823/50000 [00:29<00:02, 1464.36it/s]\rExporting train:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588    | 45978/50000 [00:29<00:02, 1486.34it/s]\rExporting train:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 46128/50000 [00:29<00:02, 1457.83it/s]\rExporting train:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 46275/50000 [00:29<00:02, 1419.84it/s]\rExporting train:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 46418/50000 [00:29<00:02, 1404.75it/s]\rExporting train:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 46579/50000 [00:29<00:02, 1461.93it/s]\rExporting train:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 46726/50000 [00:29<00:02, 1451.70it/s]\rExporting train:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 46874/50000 [00:30<00:02, 1458.43it/s]\rExporting train:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 47044/50000 [00:30<00:01, 1527.82it/s]\rExporting train:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 47213/50000 [00:30<00:01, 1573.82it/s]\rExporting train:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 47375/50000 [00:30<00:01, 1585.91it/s]\rExporting train:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 47543/50000 [00:30<00:01, 1613.11it/s]\rExporting train:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 47705/50000 [00:30<00:01, 1586.56it/s]\rExporting train:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 47880/50000 [00:30<00:01, 1634.00it/s]\rExporting train:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 48044/50000 [00:30<00:01, 1525.29it/s]\rExporting train:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 48205/50000 [00:30<00:01, 1547.64it/s]\rExporting train:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 48361/50000 [00:31<00:01, 1482.01it/s]\rExporting train:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 48511/50000 [00:31<00:01, 1470.89it/s]\rExporting train:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 48659/50000 [00:31<00:00, 1417.75it/s]\rExporting train:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 48802/50000 [00:31<00:00, 1367.93it/s]\rExporting train:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 48959/50000 [00:31<00:00, 1423.22it/s]\rExporting train:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 49116/50000 [00:31<00:00, 1463.07it/s]\rExporting train:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 49270/50000 [00:31<00:00, 1484.79it/s]\rExporting train:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 49420/50000 [00:31<00:00, 1468.00it/s]\rExporting train:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 49568/50000 [00:31<00:00, 1469.94it/s]\rExporting train:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 49735/50000 [00:31<00:00, 1526.89it/s]\rExporting train: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 49889/50000 [00:32<00:00, 1485.22it/s]\rExporting train: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50000/50000 [00:32<00:00, 1556.02it/s]\n",
            "\rExporting val:   0%|                                                                  | 0/5000 [00:00<?, ?it/s]\rExporting val:   3%|\u2588\u258a                                                    | 167/5000 [00:00<00:02, 1667.78it/s]\rExporting val:   7%|\u2588\u2588\u2588\u258b                                                  | 336/5000 [00:00<00:02, 1677.89it/s]\rExporting val:  10%|\u2588\u2588\u2588\u2588\u2588\u258d                                                | 504/5000 [00:00<00:02, 1663.92it/s]\rExporting val:  14%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                              | 684/5000 [00:00<00:02, 1714.98it/s]\rExporting val:  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                            | 861/5000 [00:00<00:02, 1733.97it/s]\rExporting val:  21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                          | 1035/5000 [00:00<00:02, 1716.48it/s]\rExporting val:  24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                        | 1207/5000 [00:00<00:02, 1624.47it/s]\rExporting val:  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                      | 1371/5000 [00:00<00:02, 1591.42it/s]\rExporting val:  31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                    | 1548/5000 [00:00<00:02, 1642.53it/s]\rExporting val:  35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                  | 1726/5000 [00:01<00:01, 1681.98it/s]\rExporting val:  38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                | 1899/5000 [00:01<00:01, 1695.18it/s]\rExporting val:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                               | 2076/5000 [00:01<00:01, 1717.52it/s]\rExporting val:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                             | 2249/5000 [00:01<00:01, 1717.00it/s]\rExporting val:  48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                           | 2421/5000 [00:01<00:01, 1654.56it/s]\rExporting val:  52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                         | 2588/5000 [00:01<00:01, 1580.48it/s]\rExporting val:  55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                       | 2748/5000 [00:01<00:01, 1535.01it/s]\rExporting val:  58%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                      | 2905/5000 [00:01<00:01, 1542.32it/s]\rExporting val:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                    | 3080/5000 [00:01<00:01, 1600.24it/s]\rExporting val:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                  | 3245/5000 [00:01<00:01, 1613.41it/s]\rExporting val:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                | 3414/5000 [00:02<00:00, 1635.11it/s]\rExporting val:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588               | 3590/5000 [00:02<00:00, 1670.98it/s]\rExporting val:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589             | 3771/5000 [00:02<00:00, 1710.68it/s]\rExporting val:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a           | 3943/5000 [00:02<00:00, 1705.81it/s]\rExporting val:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c         | 4114/5000 [00:02<00:00, 1667.10it/s]\rExporting val:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d       | 4282/5000 [00:02<00:00, 1596.76it/s]\rExporting val:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588      | 4443/5000 [00:02<00:00, 1533.02it/s]\rExporting val:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 4598/5000 [00:02<00:00, 1492.13it/s]\rExporting val:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 4748/5000 [00:02<00:00, 1452.22it/s]\rExporting val:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 4894/5000 [00:03<00:00, 1431.91it/s]\rExporting val: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:03<00:00, 1608.11it/s]\n",
            "\rExporting test:   0%|                                                                 | 0/5000 [00:00<?, ?it/s]\rExporting test:   3%|\u2588\u258b                                                   | 164/5000 [00:00<00:02, 1635.37it/s]\rExporting test:   7%|\u2588\u2588\u2588\u258c                                                 | 341/5000 [00:00<00:02, 1711.41it/s]\rExporting test:  10%|\u2588\u2588\u2588\u2588\u2588\u258d                                               | 513/5000 [00:00<00:02, 1586.68it/s]\rExporting test:  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                             | 673/5000 [00:00<00:02, 1560.30it/s]\rExporting test:  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                            | 830/5000 [00:00<00:02, 1511.49it/s]\rExporting test:  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                          | 982/5000 [00:00<00:02, 1468.42it/s]\rExporting test:  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                        | 1130/5000 [00:00<00:02, 1407.98it/s]\rExporting test:  25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                      | 1272/5000 [00:00<00:02, 1393.82it/s]\rExporting test:  28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                     | 1412/5000 [00:00<00:02, 1338.86it/s]\rExporting test:  31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                    | 1547/5000 [00:01<00:02, 1305.21it/s]\rExporting test:  34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 1691/5000 [00:01<00:02, 1342.33it/s]\rExporting test:  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                 | 1834/5000 [00:01<00:02, 1367.62it/s]\rExporting test:  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                               | 1980/5000 [00:01<00:02, 1394.56it/s]\rExporting test:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                              | 2120/5000 [00:01<00:02, 1367.29it/s]\rExporting test:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 2269/5000 [00:01<00:01, 1400.76it/s]\rExporting test:  48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                           | 2410/5000 [00:01<00:01, 1314.95it/s]\rExporting test:  51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                         | 2548/5000 [00:01<00:01, 1332.72it/s]\rExporting test:  54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                        | 2696/5000 [00:01<00:01, 1374.55it/s]\rExporting test:  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                      | 2849/5000 [00:02<00:01, 1419.15it/s]\rExporting test:  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                     | 2992/5000 [00:02<00:01, 1414.54it/s]\rExporting test:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                   | 3134/5000 [00:02<00:01, 1348.49it/s]\rExporting test:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                  | 3277/5000 [00:02<00:01, 1371.28it/s]\rExporting test:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                | 3428/5000 [00:02<00:01, 1410.39it/s]\rExporting test:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f              | 3570/5000 [00:02<00:01, 1402.29it/s]\rExporting test:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c             | 3711/5000 [00:02<00:00, 1395.93it/s]\rExporting test:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588            | 3851/5000 [00:02<00:00, 1389.51it/s]\rExporting test:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b          | 4010/5000 [00:02<00:00, 1447.78it/s]\rExporting test:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f        | 4157/5000 [00:02<00:00, 1452.50it/s]\rExporting test:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a       | 4304/5000 [00:03<00:00, 1456.68it/s]\rExporting test:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e     | 4458/5000 [00:03<00:00, 1479.91it/s]\rExporting test:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589    | 4607/5000 [00:03<00:00, 1439.69it/s]\rExporting test:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 4760/5000 [00:03<00:00, 1465.57it/s]\rExporting test:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 4933/5000 [00:03<00:00, 1542.09it/s]\rExporting test: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:03<00:00, 1430.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DONE] CIFAR-10 exported to: /root/data/cifar10_extracted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare DataLoaders\n",
        "\n",
        "Define the dataset root and load the training, validation, and test datasets using the custom `ClassificationDataset` class.  Set the number of workers depending on whether a GPU is available.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# Path to your dataset root directory. This folder contains 'train', 'val', and 'test' subfolders.\n",
        "data_root = str(Path(\"/root/data/cifar10_extracted\").resolve())\n",
        "\n",
        "# Image size used for resizing. ConvNeXt models typically expect 224\u00d7224 inputs.\n",
        "img_size = 224\n",
        "\n",
        "# Number of worker processes for data loading. Adjust based on your CPU cores and GPU. A fallback of 0 for CPU-only.\n",
        "num_workers = 4 if torch.cuda.is_available() else 0\n",
        "\n",
        "# Define transforms for training and validation/test using our custom transform\n",
        "transform_train = ClassificationTransform(size=img_size, train=True)\n",
        "transform_val   = ClassificationTransform(size=img_size, train=False)\n",
        "\n",
        "# Load training dataset and determine class mapping\n",
        "ds_train = ClassificationDataset(data_root, 'train', transform_train)\n",
        "class_to_idx = ds_train.class_to_idx\n",
        "num_classes = len(class_to_idx)\n",
        "if num_classes < 2:\n",
        "    raise RuntimeError('Need at least two classes in the training data.')\n",
        "\n",
        "# Choose which split to use for validation: we explicitly have a 'val' folder\n",
        "val_split_name = 'val'\n",
        "\n",
        "# Load validation and test datasets with the same class mapping\n",
        "ds_val  = ClassificationDataset(data_root, val_split_name, transform_val, class_to_idx=class_to_idx)\n",
        "ds_test = ClassificationDataset(data_root, 'test', transform_val, class_to_idx=class_to_idx)\n",
        "\n",
        "print(f\"Classes ({num_classes}): {list(class_to_idx.keys())}\")\n",
        "print(f\"Train: {len(ds_train)}, Val: {len(ds_val)}, Test: {len(ds_test)}\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes (10): ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Train: 50000, Val: 5000, Test: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logging Helpers\n",
        "\n",
        "Utilities to save per-epoch metrics into CSV files and to generate line plots and confusion matrices.  All artifacts are written under the `./artifacts` directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# Directory to store artifacts (CSV logs, curves, checkpoints)\n",
        "ARTIFACT_ROOT = Path(\"./artifacts/cifar10_optuna\")\n",
        "ARTIFACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Flag to evaluate test set each epoch (be cautious of leakage).  Set True to log test metrics per epoch.\n",
        "EVAL_TEST_EACH_EPOCH = True\n",
        "\n",
        "def _now():\n",
        "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
        "\n",
        "\n",
        "def save_epoch_logcsv(\n",
        "    out_dir: Path,\n",
        "    trial_num: int,\n",
        "    split: str,\n",
        "    epoch: int,\n",
        "    metrics: Dict[str, float],\n",
        "    extra: Dict[str, str] = None\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Append an epoch line into out_dir/'epoch_logs.csv' with columns:\n",
        "    time, trial, split, epoch, loss, acc, precision, recall, f1, specificity, <extras...>\n",
        "    \"\"\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    fpath = out_dir / \"epoch_logs.csv\"\n",
        "\n",
        "    row = {\n",
        "        \"time\": _now(),\n",
        "        \"trial\": trial_num,\n",
        "        \"split\": split,\n",
        "        \"epoch\": epoch,\n",
        "        \"loss\": metrics.get(\"loss\", None),\n",
        "        \"acc\": metrics.get(\"acc\", None),\n",
        "        \"precision\": metrics.get(\"precision\", None),\n",
        "        \"recall\": metrics.get(\"recall\", None),\n",
        "        \"f1\": metrics.get(\"f1\", None),\n",
        "        \"specificity\": metrics.get(\"specificity\", None),\n",
        "    }\n",
        "    if extra:\n",
        "        row.update(extra)\n",
        "\n",
        "    write_header = not fpath.exists()\n",
        "    with open(fpath, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=list(row.keys()))\n",
        "        if write_header:\n",
        "            w.writeheader()\n",
        "        w.writerow(row)\n",
        "\n",
        "\n",
        "def plot_lines(line_dict: Dict[str, List[float]], title: str, x_label: str, y_label: str, out_path: Path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    if not line_dict:\n",
        "        return\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    max_len = max(len(v) for v in line_dict.values())\n",
        "    epochs = range(1, max_len + 1)\n",
        "    for name, y in line_dict.items():\n",
        "        plt.plot(epochs[:len(y)], y, label=name, linewidth=2)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix_matplotlib(cm: np.ndarray, class_names: List[str], out_path: Path, title: str = \"Confusion Matrix\"):\n",
        "    import matplotlib.pyplot as plt\n",
        "    if cm.size == 0:\n",
        "        return\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    thresh = cm.max() / 2.0 if cm.max() > 0 else 0\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(int(cm[i, j])), ha=\"center\", va=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path)\n",
        "    plt.close()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optuna Objective Function\n",
        "\n",
        "Define the objective function for Optuna.  For each trial, the model is trained for a small number of epochs with sampled hyperparameters.  Metrics for train, validation, and test (if enabled) are logged to CSV files, and loss/accuracy curves along with confusion matrices are generated for each trial.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "def objective(trial: optuna.Trial) -> float:\n",
        "    # ===== hyperparameters =====\n",
        "    lr        = trial.suggest_float('lr', 1e-5, 5e-3, log=True)\n",
        "    wd        = trial.suggest_float('weight_decay', 1e-6, 5e-3, log=True)\n",
        "    dropout   = trial.suggest_float('dropout', 0.0, 0.4)\n",
        "    opt_name  = trial.suggest_categorical('optimizer', ['adamw', 'sgd'])\n",
        "    batch_size= trial.suggest_categorical('batch_size', [8, 16])\n",
        "    # Force epochs to a fixed small integer for tuning\n",
        "    epochs    = trial.suggest_int('epochs', 3, 3)  # small for tuning\n",
        "\n",
        "    # Print the sampled hyperparameters for this trial\n",
        "    print(f\"Starting Trial {trial.number}: lr={lr:.5f}, wd={wd:.6f}, dropout={dropout:.2f}, optimizer={opt_name}, batch_size={batch_size}, epochs={epochs}\", flush=True)\n",
        "\n",
        "    device = device_auto()\n",
        "\n",
        "    # ===== DataLoaders (uses global num_workers) =====\n",
        "    dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
        "    dl_val   = DataLoader(ds_val,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "    dl_test  = DataLoader(ds_test,  batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    # ===== Model & Optimizer =====\n",
        "    model = build_convnext_classifier(MANUAL_CONVNEXT_VARIANT, num_classes, dropout).to(device)\n",
        "    optimizer = (torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "                 if opt_name == 'adamw'\n",
        "                 else torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9, nesterov=True))\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # ===== Logs for curves =====\n",
        "    tr_losses, tr_accs = [], []\n",
        "    va_losses, va_accs = [], []\n",
        "    te_losses, te_accs = [], []\n",
        "\n",
        "    # Directory for this trial\n",
        "    out_trial_dir = ARTIFACT_ROOT / f\"trial_{trial.number:03d}\"\n",
        "    out_trial_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    best_acc = -1.0\n",
        "    best_ckpt = out_trial_dir / \"best_model.pth\"\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        # ---- train ----\n",
        "        tr_loss, tr_acc = train_one_epoch_cls(model, dl_train, optimizer, criterion, device, epoch-1, epochs)\n",
        "        tr_losses.append(tr_loss); tr_accs.append(tr_acc)\n",
        "        save_epoch_logcsv(out_trial_dir, trial.number, \"train\", epoch, {\n",
        "            \"loss\": tr_loss, \"acc\": tr_acc, \"precision\": None, \"recall\": None, \"f1\": None, \"specificity\": None\n",
        "        })\n",
        "\n",
        "        # ---- val ----\n",
        "        val_metrics = eval_cls_metrics(model, dl_val, criterion, device)\n",
        "        va_losses.append(val_metrics['loss']); va_accs.append(val_metrics['acc'])\n",
        "        save_epoch_logcsv(out_trial_dir, trial.number, \"val\", epoch, val_metrics)\n",
        "\n",
        "        # Print train and validation metrics for this epoch\n",
        "        print(f\"Trial {trial.number} Epoch {epoch}/{epochs} - Train loss: {tr_loss:.4f}, acc: {tr_acc:.4f}; Val loss: {val_metrics['loss']:.4f}, acc: {val_metrics['acc']:.4f}\", flush=True)\n",
        "\n",
        "        # ---- test (optional) ----\n",
        "        if EVAL_TEST_EACH_EPOCH:\n",
        "            test_metrics = eval_cls_metrics(model, dl_test, criterion, device)\n",
        "            te_losses.append(test_metrics['loss']); te_accs.append(test_metrics['acc'])\n",
        "            save_epoch_logcsv(out_trial_dir, trial.number, \"test\", epoch, test_metrics)\n",
        "            # Print test metrics for this epoch\n",
        "            print(f\"Trial {trial.number} Epoch {epoch}/{epochs} - Test loss: {test_metrics['loss']:.4f}, acc: {test_metrics['acc']:.4f}\", flush=True)\n",
        "\n",
        "        # Report to Optuna (minimize 1 - val_acc)\n",
        "        trial.report(1.0 - val_metrics['acc'], step=epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "        # Save best by val acc\n",
        "        if val_metrics['acc'] > best_acc:\n",
        "            best_acc = val_metrics['acc']\n",
        "            torch.save({\n",
        "                \"model\": model.state_dict(),\n",
        "                \"variant\": MANUAL_CONVNEXT_VARIANT,\n",
        "                \"num_classes\": num_classes,\n",
        "                \"classes\": list(class_to_idx.keys())\n",
        "            }, best_ckpt)\n",
        "\n",
        "    # curves\n",
        "    plot_lines({\"Train Loss\": tr_losses, \"Val Loss\": va_losses},\n",
        "               \"Train vs Val Loss\", \"Epoch\", \"Loss\", out_trial_dir / \"loss_curve.png\")\n",
        "    plot_lines({\"Train Acc\": tr_accs, \"Val Acc\": va_accs},\n",
        "               \"Train vs Val Accuracy\", \"Epoch\", \"Accuracy\", out_trial_dir / \"acc_curve.png\")\n",
        "    if EVAL_TEST_EACH_EPOCH and te_losses:\n",
        "        plot_lines({\"Test Loss\": te_losses}, \"Test Loss\", \"Epoch\", \"Loss\", out_trial_dir / \"test_loss_curve.png\")\n",
        "    if EVAL_TEST_EACH_EPOCH and te_accs:\n",
        "        plot_lines({\"Test Acc\": te_accs}, \"Test Accuracy\", \"Epoch\", \"Accuracy\", out_trial_dir / \"test_acc_curve.png\")\n",
        "\n",
        "    # final confusion matrix on VAL and TEST of final epoch\n",
        "    with torch.no_grad():\n",
        "        # VAL\n",
        "        all_preds_cm, all_labels_cm = [], []\n",
        "        for x_val, y_val in dl_val:\n",
        "            x_val = x_val.to(device, non_blocking=True)\n",
        "            y_val = y_val.to(device, non_blocking=True)\n",
        "            logits_val = model(x_val)\n",
        "            all_preds_cm.append(logits_val.argmax(1).detach().cpu().numpy())\n",
        "            all_labels_cm.append(y_val.detach().cpu().numpy())\n",
        "        if all_labels_cm:\n",
        "            y_true_cm = np.concatenate(all_labels_cm)\n",
        "            y_pred_cm = np.concatenate(all_preds_cm)\n",
        "            cm_val = confusion_matrix(y_true_cm, y_pred_cm)\n",
        "            plot_confusion_matrix_matplotlib(cm_val, list(class_to_idx.keys()), out_trial_dir / \"val_confusion_matrix.png\", \"Validation Confusion Matrix\")\n",
        "        # TEST\n",
        "        if EVAL_TEST_EACH_EPOCH:\n",
        "            all_preds_cm, all_labels_cm = [], []\n",
        "            for x_te, y_te in dl_test:\n",
        "                x_te = x_te.to(device, non_blocking=True)\n",
        "                y_te = y_te.to(device, non_blocking=True)\n",
        "                logits_te = model(x_te)\n",
        "                all_preds_cm.append(logits_te.argmax(1).detach().cpu().numpy())\n",
        "                all_labels_cm.append(y_te.detach().cpu().numpy())\n",
        "            if all_labels_cm:\n",
        "                y_true_cm = np.concatenate(all_labels_cm)\n",
        "                y_pred_cm = np.concatenate(all_preds_cm)\n",
        "                cm_test = confusion_matrix(y_true_cm, y_pred_cm)\n",
        "                plot_confusion_matrix_matplotlib(cm_test, list(class_to_idx.keys()), out_trial_dir / \"test_confusion_matrix.png\", \"Test Confusion Matrix\")\n",
        "\n",
        "    # Print final result of trial\n",
        "    print(f\"Finished Trial {trial.number}. Best validation accuracy: {best_acc:.4f}\", flush=True)\n",
        "\n",
        "    # objective: minimize 1 - best val acc\n",
        "    return 1.0 - float(best_acc)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Optimization with Optuna\n",
        "\n",
        "Create an Optuna study, run a few trials, and report the best hyperparameters found.  The number of trials is set small by default to keep runtime reasonable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# Reset Optuna logging level to show information\n",
        "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "\n",
        "# Callback to print results at the end of each trial\n",
        "\n",
        "def print_callback(study, trial):\n",
        "    print(f\"[Optuna] Trial {trial.number} finished with value: {trial.value:.4f}, params: {trial.params}\", flush=True)\n",
        "    print(f\"[Optuna]     Best value so far: {study.best_value:.4f}\", flush=True)\n",
        "\n",
        "seed_everything(42)\n",
        "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=1, timeout=None, callbacks=[print_callback])\n",
        "\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "best_trial = study.best_trial\n",
        "\n",
        "print('Best trial:')\n",
        "print(f\"Validation accuracy: {1.0 - best_trial.value:.4f}\")\n",
        "print('Hyperparameters:')\n",
        "for key, value in best_trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-25 02:24:33,433] A new study created in memory with name: no-name-0cc273d4-4ae7-4b77-b666-689035e63f97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Trial 0: lr=0.00010, wd=0.003286, dropout=0.29, optimizer=adamw, batch_size=8, epochs=3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bb2e2c175db4f42af799043d5362fe0",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 Epoch 1/3 - Train loss: 0.6321, acc: 0.7788; Val loss: 0.2591, acc: 0.9102\n",
            "Trial 0 Epoch 1/3 - Test loss: 0.2839, acc: 0.8996\n",
            "Trial 0 Epoch 2/3 - Train loss: 0.2731, acc: 0.9069; Val loss: 0.2488, acc: 0.9158\n",
            "Trial 0 Epoch 2/3 - Test loss: 0.2458, acc: 0.9164\n",
            "Trial 0 Epoch 3/3 - Train loss: 0.2122, acc: 0.9278; Val loss: 0.1794, acc: 0.9396\n",
            "Trial 0 Epoch 3/3 - Test loss: 0.1853, acc: 0.9392\n",
            "Finished Trial 0. Best validation accuracy: 0.9396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-25 02:42:14,768] Trial 0 finished with value: 0.06040000000000001 and parameters: {'lr': 0.0001025350969016849, 'weight_decay': 0.0032859708169642424, 'dropout': 0.292797576724562, 'optimizer': 'adamw', 'batch_size': 8, 'epochs': 3}. Best is trial 0 with value: 0.06040000000000001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Optuna] Trial 0 finished with value: 0.0604, params: {'lr': 0.0001025350969016849, 'weight_decay': 0.0032859708169642424, 'dropout': 0.292797576724562, 'optimizer': 'adamw', 'batch_size': 8, 'epochs': 3}\n",
            "[Optuna]     Best value so far: 0.0604\n",
            "Number of finished trials: 1\n",
            "Best trial:\n",
            "Validation accuracy: 0.9396\n",
            "Hyperparameters:\n",
            "    lr: 0.0001025350969016849\n",
            "    weight_decay: 0.0032859708169642424\n",
            "    dropout: 0.292797576724562\n",
            "    optimizer: adamw\n",
            "    batch_size: 8\n",
            "    epochs: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Training with Best Hyperparameters\n",
        "\n",
        "Train a fresh model using the best hyperparameters discovered by Optuna.  Record metrics for train, validation, and test sets at each epoch, produce curves, and generate confusion matrices for the final epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# Retrieve the best hyperparameters\n",
        "best_params = study.best_trial.params\n",
        "# Number of epochs for the final training run\n",
        "final_epochs    = int(best_params.get('epochs', 5))\n",
        "final_batchsize = int(best_params.get('batch_size', 16))\n",
        "final_lr        = float(best_params['lr'])\n",
        "final_wd        = float(best_params['weight_decay'])\n",
        "final_dropout   = float(best_params['dropout'])\n",
        "final_opt_name  = best_params['optimizer']\n",
        "\n",
        "# Set up directory for final run\n",
        "final_dir = ARTIFACT_ROOT / \"final_best_run\"\n",
        "final_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# DataLoaders\n",
        "device = device_auto()\n",
        "final_dl_train = DataLoader(ds_train, batch_size=final_batchsize, shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
        "final_dl_val   = DataLoader(ds_val,   batch_size=final_batchsize, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "final_dl_test  = DataLoader(ds_test,  batch_size=final_batchsize, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "# Model & optimizer\n",
        "final_model = build_convnext_classifier(MANUAL_CONVNEXT_VARIANT, num_classes, final_dropout).to(device)\n",
        "final_optimizer = (torch.optim.AdamW(final_model.parameters(), lr=final_lr, weight_decay=final_wd)\n",
        "                   if final_opt_name == 'adamw'\n",
        "                   else torch.optim.SGD(final_model.parameters(), lr=final_lr, weight_decay=final_wd, momentum=0.9, nesterov=True))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Containers to store metrics\n",
        "train_losses, train_accs = [], []\n",
        "val_losses, val_accs     = [], []\n",
        "test_losses, test_accs   = [], []\n",
        "\n",
        "best_val_acc = -1.0\n",
        "best_ckpt = final_dir / \"best_model.pth\"\n",
        "\n",
        "for epoch in range(1, final_epochs+1):\n",
        "    # Train\n",
        "    tr_loss, tr_acc = train_one_epoch_cls(final_model, final_dl_train, final_optimizer, criterion, device, epoch-1, final_epochs)\n",
        "    train_losses.append(tr_loss); train_accs.append(tr_acc)\n",
        "    save_epoch_logcsv(final_dir, -1, \"train\", epoch, {\n",
        "        \"loss\": tr_loss, \"acc\": tr_acc, \"precision\": None, \"recall\": None, \"f1\": None, \"specificity\": None\n",
        "    })\n",
        "\n",
        "    # Validate\n",
        "    val_metrics = eval_cls_metrics(final_model, final_dl_val, criterion, device)\n",
        "    val_losses.append(val_metrics['loss']); val_accs.append(val_metrics['acc'])\n",
        "    save_epoch_logcsv(final_dir, -1, \"val\", epoch, val_metrics)\n",
        "\n",
        "    # Test\n",
        "    test_metrics = None\n",
        "    if EVAL_TEST_EACH_EPOCH:\n",
        "        test_metrics = eval_cls_metrics(final_model, final_dl_test, criterion, device)\n",
        "        test_losses.append(test_metrics['loss']); test_accs.append(test_metrics['acc'])\n",
        "        save_epoch_logcsv(final_dir, -1, \"test\", epoch, test_metrics)\n",
        "\n",
        "    # Print metrics for this epoch\n",
        "    msg = f\"Epoch {epoch}/{final_epochs} - Train loss: {tr_loss:.4f}, acc: {tr_acc:.4f}; Val loss: {val_metrics['loss']:.4f}, acc: {val_metrics['acc']:.4f}\"\n",
        "    if test_metrics is not None:\n",
        "        msg += f\"; Test loss: {test_metrics['loss']:.4f}, acc: {test_metrics['acc']:.4f}\"\n",
        "    print(msg, flush=True)\n",
        "\n",
        "    # Save best based on validation accuracy\n",
        "    if val_metrics['acc'] > best_val_acc:\n",
        "        best_val_acc = val_metrics['acc']\n",
        "        torch.save({\n",
        "            \"model\": final_model.state_dict(),\n",
        "            \"variant\": MANUAL_CONVNEXT_VARIANT,\n",
        "            \"num_classes\": num_classes,\n",
        "            \"classes\": list(class_to_idx.keys())\n",
        "        }, best_ckpt)\n",
        "\n",
        "# Generate curves for the final run\n",
        "plot_lines({\"Train Loss\": train_losses, \"Val Loss\": val_losses}, \"Final: Train vs Val Loss\", \"Epoch\", \"Loss\", final_dir/\"loss_curve.png\")\n",
        "plot_lines({\"Train Acc\": train_accs, \"Val Acc\": val_accs}, \"Final: Train vs Val Accuracy\", \"Epoch\", \"Accuracy\", final_dir/\"acc_curve.png\")\n",
        "if EVAL_TEST_EACH_EPOCH and test_losses:\n",
        "    plot_lines({\"Test Loss\": test_losses}, \"Final: Test Loss\", \"Epoch\", \"Loss\", final_dir/\"test_loss_curve.png\")\n",
        "if EVAL_TEST_EACH_EPOCH and test_accs:\n",
        "    plot_lines({\"Test Acc\": test_accs}, \"Final: Test Accuracy\", \"Epoch\", \"Accuracy\", final_dir/\"test_acc_curve.png\")\n",
        "\n",
        "# Confusion matrices for final epoch (val and test)\n",
        "with torch.no_grad():\n",
        "    # Validation\n",
        "    preds, labels = [], []\n",
        "    for x_val, y_val in final_dl_val:\n",
        "        x_val = x_val.to(device, non_blocking=True)\n",
        "        y_val = y_val.to(device, non_blocking=True)\n",
        "        logits_val = final_model(x_val)\n",
        "        preds.append(logits_val.argmax(1).detach().cpu().numpy())\n",
        "        labels.append(y_val.detach().cpu().numpy())\n",
        "    if labels:\n",
        "        y_true = np.concatenate(labels)\n",
        "        y_pred = np.concatenate(preds)\n",
        "        cm_val = confusion_matrix(y_true, y_pred)\n",
        "        plot_confusion_matrix_matplotlib(cm_val, list(class_to_idx.keys()), final_dir/\"val_confusion_matrix.png\", \"Final Validation Confusion Matrix\")\n",
        "\n",
        "    # Test\n",
        "    if EVAL_TEST_EACH_EPOCH:\n",
        "        preds, labels = [], []\n",
        "        for x_te, y_te in final_dl_test:\n",
        "            x_te = x_te.to(device, non_blocking=True)\n",
        "            y_te = y_te.to(device, non_blocking=True)\n",
        "            logits_te = final_model(x_te)\n",
        "            preds.append(logits_te.argmax(1).detach().cpu().numpy())\n",
        "            labels.append(y_te.detach().cpu().numpy())\n",
        "        if labels:\n",
        "            y_true = np.concatenate(labels)\n",
        "            y_pred = np.concatenate(preds)\n",
        "            cm_test = confusion_matrix(y_true, y_pred)\n",
        "            plot_confusion_matrix_matplotlib(cm_test, list(class_to_idx.keys()), final_dir/\"test_confusion_matrix.png\", \"Final Test Confusion Matrix\")\n",
        "\n",
        "print(f\"[DONE] Final training complete. Logs and plots are stored in {final_dir}\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Train loss: 0.4552, acc: 0.8492; Val loss: 0.2387, acc: 0.9202; Test loss: 0.2589, acc: 0.9176\n",
            "Epoch 2/3 - Train loss: 0.2710, acc: 0.9093; Val loss: 0.2354, acc: 0.9170; Test loss: 0.2327, acc: 0.9238\n",
            "Epoch 3/3 - Train loss: 0.2115, acc: 0.9289; Val loss: 0.1774, acc: 0.9424; Test loss: 0.1947, acc: 0.9382\n",
            "[DONE] Final training complete. Logs and plots are stored in artifacts/cifar10_optuna/final_best_run\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}